# FIAP â€” Fase 6 (Parte 2) â€¢ FarmTech Solutions
**ComparaÃ§Ã£o YOLOv5 (baseline e custom) vs CNN do zero**

> Este repositÃ³rio contÃ©m a **Entrega 2** da Fase 6 do PBL: comparaÃ§Ã£o entre **YOLOv5 padrÃ£o**, **YOLOv5 customizada** (pesos da Entrega 1) e **CNN do zero** (classificaÃ§Ã£o), **usando a mesma base** preparada na Entrega 1.

## ğŸ§­ SumÃ¡rio
- [VisÃ£o Geral](#-visÃ£o-geral)
- [PrÃ©-requisitos](#-prÃ©-requisitos)
- [Estrutura do Dataset](#-estrutura-do-dataset)
- [Como Executar (Google Colab)](#-como-executar-google-colab)
- [O que Preencher/Editar](#-o-que-preenchereditar)
- [SaÃ­das e EvidÃªncias](#-saÃ­das-e-evidÃªncias)
- [ComparaÃ§Ã£o e ConclusÃµes](#-comparaÃ§Ã£o-e-conclusÃµes)
- [GravaÃ§Ã£o do VÃ­deo (5 min)](#-gravaÃ§Ã£o-do-vÃ­deo-5-min)
- [SoluÃ§Ã£o TÃ©cnica](#-soluÃ§Ã£o-tÃ©cnica)
- [CrÃ©ditos](#-crÃ©ditos)
- [LicenÃ§a](#-licenÃ§a)

---

## ğŸ” VisÃ£o Geral
- **Objetivo**: avaliar criticamente trÃªs abordagens sobre a **mesma base**:
  1. **YOLOv5 PadrÃ£o (baseline)** â€” treino rÃ¡pido com hiperparÃ¢metros default.
  2. **YOLOv5 Custom** â€” **reaproveita os pesos (best.pt)** treinados na Entrega 1.
  3. **CNN do zero (Keras/TensorFlow)** â€” classificaÃ§Ã£o por classes (sem *bounding boxes*).

- **CritÃ©rios comparados**:
  - Facilidade de uso/integraÃ§Ã£o
  - PrecisÃ£o (mAP/Accuracy/F1)
  - Tempo de treinamento/customizaÃ§Ã£o
  - Tempo de inferÃªncia (latÃªncia s/imagem)

---

## âœ… PrÃ©-requisitos
- Google Colab com **GPU ativada** (Runtime â†’ Change runtime type â†’ **GPU**).
- **Google Drive** com:
  - `dataset.yaml` no formato YOLO (com `train`, `val`, `test` e `names`).
  - Pastas `images/` e `labels/` com as anotaÃ§Ãµes **YOLO** da Entrega 1.
  - **Pesos customizados** da Entrega 1: `.../runs/train/expX/weights/best.pt`.
- Python â‰¥ 3.10 (gerenciado pelo Colab).
- EspaÃ§o livre no Drive para salvar resultados.

---

## ğŸ—‚ï¸ Estrutura do Dataset
Exemplo (sugestivo, adapte ao seu):

/MyDrive/fase6/
  dataset/
    dataset.yaml
  images/
    train/...
    val/...
    test/...
    labels/
    train/...
    val/...
    test/...
  yolo_runs/ # 


**AtenÃ§Ã£o**: o `dataset.yaml` deve apontar corretamente para os caminhos de `train`, `val` e `test` (pasta ou arquivo .txt com a lista de imagens) e conter `names` com a lista das classes.

---

## â–¶ï¸ Como Executar (Google Colab)
1. Abra o notebook **`parte2_fase6_farmtech_yolo_cnn.ipynb`** no Colab.  
2. Execute a cÃ©lula **Montar Google Drive**.  
3. **Edite os caminhos** no bloco â€œğŸ”§ ConfiguraÃ§Ã£o de caminhos (EDITE AQUI)â€.  
   - `DATASET_YAML_PATH` â†’ seu `dataset.yaml`  
   - `CUSTOM_WEIGHTS_PATH` â†’ `best.pt` (Entrega 1)  
   - `OUTPUT_DIR` â†’ pasta de saÃ­da no Drive  
4. Execute as seÃ§Ãµes na ordem (setup â†’ YOLO baseline â†’ avaliaÃ§Ã£o custom â†’ conversÃ£o â†’ CNN â†’ comparaÃ§Ã£o).  
5. Ao final, colete as evidÃªncias (imagens, mÃ©tricas e CSV/JSON) para o README e para o vÃ­deo.

---

## âœï¸ O que Preencher/Editar
No topo do notebook:
- **Autor/RM** (no cabeÃ§alho Markdown).
- `DATASET_YAML_PATH`, `CUSTOM_WEIGHTS_PATH`, `OUTPUT_DIR`.
- Na seÃ§Ã£o **â€œDiscussÃ£o e ConclusÃµesâ€**, substitua os placeholders (**X/Y/Z**) pelos seus resultados.

---

## ğŸ“¦ SaÃ­das e EvidÃªncias
O notebook gera automaticamente:

- **YOLOv5 baseline**
  - Treino: `/content/yolo_runs/fase6_yolo_baseline/...`
  - ValidaÃ§Ã£o (test): `/content/yolo_val/fase6_yolo_baseline_test/...`

- **YOLOv5 custom (Entrega 1)**
  - ValidaÃ§Ã£o (test): `/content/yolo_val/fase6_yolo_custom_test/...`

- **InferÃªncias (prints)**
  - `/content/yolo_detect/baseline/...`
  - `/content/yolo_detect/custom/...`

- **CNN (classificaÃ§Ã£o)**
  - Pesos: `/content/cnn_baseline.h5`
  - Matriz de confusÃ£o: `cnn_confusion_matrix.png` (em `OUTPUT_DIR`)
  - MÃ©tricas: `cnn_metrics.json` (em `OUTPUT_DIR`)

- **Comparativos consolidados**
  - `comparativo_metrics.json`
  - `comparativo_metrics_table.csv`

> **Inclua no README** algumas imagens de detecÃ§Ã£o (`yolo_detect/...`) e a matriz de confusÃ£o da CNN.

---

## ğŸ“Š ComparaÃ§Ã£o e ConclusÃµes
ApÃ³s rodar, preencha uma tabela de sÃ­ntese como:

| Modelo            | Facilidade | PrecisÃ£o (mAP/Acc/F1) | Treino (min) | LatÃªncia (s/img) | ObservaÃ§Ãµes |
|-------------------|------------|------------------------|--------------|------------------|------------|
| YOLOv5 Baseline   | Alta       | mAP@50=â€¦ / mAP@50-95=â€¦ | â€¦            | â€¦                | Setup rÃ¡pido |
| YOLOv5 Custom     | MÃ©dia      | **mAP@50=â€¦**           | â€¦            | **â€¦**            | Melhor no meu dataset |
| CNN (Keras)       | MÃ©dia      | Acc=â€¦ / F1=â€¦           | â€¦            | â€¦                | Sem caixas (classificaÃ§Ã£o) |

**ConclusÃ£o sugerida**: para cenÃ¡rios de **detecÃ§Ã£o em tempo real** (p. ex., seguranÃ§a patrimonial), **YOLO custom** tende a equilibrar **alta precisÃ£o** e **baixa latÃªncia**. A **CNN** Ã© adequada para **classificaÃ§Ã£o pura** (classe por imagem), com implementaÃ§Ã£o simples, porÃ©m nÃ£o fornece *bounding boxes*.

---

## ğŸ¥ GravaÃ§Ã£o do VÃ­deo (5 min)
- Mostre o **dataset.yaml** e a estrutura das pastas.
- Mostre de 1 a 2 **prints** das detecÃ§Ãµes (baseline vs custom).
- Mostre a **matriz de confusÃ£o** e **mÃ©tricas** da CNN.
- Mostre a **tabela comparativa** (`comparativo_metrics_table.csv`) e cite a conclusÃ£o.

---

## ğŸ§  SoluÃ§Ã£o TÃ©cnica
- **YOLOv5** (Ultralytics) para baseline e avaliaÃ§Ã£o dos pesos custom (`val.py`, `detect.py`).
- **ConversÃ£o YOLO â†’ ClassificaÃ§Ã£o**: seleciona **classe dominante** por imagem; empates sÃ£o ignorados para a CNN.
- **CNN (Keras/TensorFlow)**: `Conv2D â†’ MaxPool â†’ Conv2D â†’ MaxPool â†’ Conv2D â†’ Flatten â†’ Dense â†’ Dropout â†’ Dense(softmax)`.
- **MÃ©tricas**:
  - YOLO: *results.txt* (mAP@50, mAP@50-95, etc.).
  - CNN: Accuracy, Precision, Recall, F1 (weighted), **latÃªncia** (s/imagem).
- **ConsolidaÃ§Ã£o**: CSV/JSON com latÃªncias e mÃ©tricas das trÃªs abordagens.

---

## ğŸ‘¤ CrÃ©ditos
- **Autor**: `<Seu Nome Completo>` â€” **RM**: `<Seu RM>`
- **Grupo**: `<1 a 5 pessoas>` (se aplicÃ¡vel)

---

## ğŸ“ LicenÃ§a
Este projeto Ã© distribuÃ­do sob a licenÃ§a **MIT**. Veja `LICENSE` para mais detalhes.

