{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# ðŸŽ¯ FarmTech Vision Solutions - Sistema de DetecÃ§Ã£o com YOLOv5\n",
    "\n",
    "**Projeto:** Fase 6 - Redes Neurais e VisÃ£o Computacional  \n",
    "**Aluna:** Stephanie  \n",
    "**RM:** 564315  \n",
    "**Curso:** InteligÃªncia Artificial - FIAP  \n",
    "**Data:** 2024  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ **Objetivos do Projeto**\n",
    "\n",
    "Este notebook implementa um sistema completo de visÃ£o computacional usando **YOLOv5** para detecÃ§Ã£o de:\n",
    "- **ðŸš— VeÃ­culos** (carros, motos, caminhÃµes)\n",
    "- **ðŸš¶ Pedestres** (pessoas caminhando)\n",
    "\n",
    "### **Experimentos Planejados:**\n",
    "1. **Treinamento com 30 Ã©pocas**\n",
    "2. **Treinamento com 60 Ã©pocas**\n",
    "3. **AnÃ¡lise comparativa de performance**\n",
    "\n",
    "### **MÃ©tricas de AvaliaÃ§Ã£o:**\n",
    "- Precision, Recall, F1-Score\n",
    "- mAP@0.5 e mAP@0.5:0.95\n",
    "- Tempo de treinamento e inferÃªncia\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "theory"
   },
   "source": [
    "## ðŸ§  **FundamentaÃ§Ã£o TeÃ³rica**\n",
    "\n",
    "### **YOLO (You Only Look Once)**\n",
    "\n",
    "O YOLO revolucionou a detecÃ§Ã£o de objetos ao tratar o problema como uma **Ãºnica regressÃ£o end-to-end**, diferente dos mÃ©todos tradicionais de duas etapas.\n",
    "\n",
    "#### **Principais InovaÃ§Ãµes:**\n",
    "\n",
    "1. **Arquitetura Unificada**: Uma Ãºnica rede neural prediz simultaneamente:\n",
    "   - Coordenadas das bounding boxes\n",
    "   - Probabilidades de classe\n",
    "   - Scores de confianÃ§a\n",
    "\n",
    "2. **Processamento Global**: Analisa a imagem inteira de uma vez, capturando contexto global\n",
    "\n",
    "3. **Velocidade**: Capaz de processar imagens em tempo real (>30 FPS)\n",
    "\n",
    "#### **YOLOv5 - Arquitetura Detalhada:**\n",
    "\n",
    "- **Backbone**: CSPDarknet53 para extraÃ§Ã£o de features hierÃ¡rquicas\n",
    "- **Neck**: PANet (Path Aggregation Network) para fusÃ£o multi-escala\n",
    "- **Head**: TrÃªs camadas de detecÃ§Ã£o para diferentes escalas de objetos\n",
    "\n",
    "#### **FunÃ§Ã£o de Perda Multi-objetivo:**\n",
    "\n",
    "```\n",
    "Loss_total = Î»_box Ã— Loss_box + Î»_obj Ã— Loss_obj + Î»_cls Ã— Loss_cls\n",
    "```\n",
    "\n",
    "Onde:\n",
    "- **Loss_box**: Erro de localizaÃ§Ã£o (coordenadas)\n",
    "- **Loss_obj**: Erro de objetividade (confianÃ§a)\n",
    "- **Loss_cls**: Erro de classificaÃ§Ã£o\n",
    "\n",
    "### **ReferÃªncias AcadÃªmicas:**\n",
    "\n",
    "1. **Redmon, J., et al. (2016)**. "You Only Look Once: Unified, Real-Time Object Detection." *CVPR*.\n",
    "2. **Bochkovskiy, A., et al. (2020)**. "YOLOv4: Optimal Speed and Accuracy of Object Detection." *arXiv*.\n",
    "3. **Jocher, G., et al. (2022)**. "ultralytics/yolov5: v7.0 - YOLOv5 SOTA Realtime Instance Segmentation."\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## âš™ï¸ **1. ConfiguraÃ§Ã£o do Ambiente**\n",
    "\n",
    "InstalaÃ§Ã£o das dependÃªncias necessÃ¡rias para o projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# InstalaÃ§Ã£o das bibliotecas principais\n",
    "!pip install ultralytics\n",
    "!pip install roboflow\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib seaborn plotly\n",
    "!pip install pandas numpy\n",
    "\n",
    "# Clonando o repositÃ³rio YOLOv5 oficial\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "print("âœ… Ambiente configurado com sucesso!")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# ImportaÃ§Ãµes necessÃ¡rias\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from google.colab import drive, files\n",
    "import zipfile\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ConfiguraÃ§Ãµes de visualizaÃ§Ã£o\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette("husl")\n",
    "\n",
    "# VerificaÃ§Ã£o do ambiente\n",
    "print(f"ðŸ”¥ PyTorch Version: {torch.__version__}")\n",
    "print(f"ðŸ–¥ï¸  CUDA Available: {torch.cuda.is_available()}")\n",
    "print(f"ðŸŽ¯ Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")\n",
    "print(f"ðŸ“Š OpenCV Version: {cv2.__version__}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drive_setup"
   },
   "source": [
    "## ðŸ’¾ **2. ConfiguraÃ§Ã£o do Google Drive**\n",
    "\n",
    "Conectando ao Google Drive para acessar o dataset e salvar resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Montando o Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Definindo caminhos do projeto\n",
    "PROJECT_PATH = '/content/drive/MyDrive/FarmTech_YOLO_Project'\n",
    "DATASET_PATH = f'{PROJECT_PATH}/dataset'\n",
    "RESULTS_PATH = f'{PROJECT_PATH}/results'\n",
    "\n",
    "# Criando estrutura de pastas\n",
    "os.makedirs(f'{DATASET_PATH}/train/images', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_PATH}/train/labels', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_PATH}/val/images', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_PATH}/val/labels', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_PATH}/test/images', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_PATH}/test/labels', exist_ok=True)\n",
    "os.makedirs(f'{RESULTS_PATH}/experiment_30_epochs', exist_ok=True)\n",
    "os.makedirs(f'{RESULTS_PATH}/experiment_60_epochs', exist_ok=True)\n",
    "\n",
    "print("ðŸ“ Estrutura de pastas criada com sucesso!")\n",
    "print(f"ðŸ“‚ Dataset Path: {DATASET_PATH}")\n",
    "print(f"ðŸ“Š Results Path: {RESULTS_PATH}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_section"
   },
   "source": [
    "## ðŸ“Š **3. PreparaÃ§Ã£o do Dataset**\n",
    "\n",
    "### **Dataset: VeÃ­culos vs Pedestres**\n",
    "\n",
    "**DistribuiÃ§Ã£o planejada:**\n",
    "- **Treinamento**: 64 imagens (32 veÃ­culos + 32 pedestres)\n",
    "- **ValidaÃ§Ã£o**: 8 imagens (4 veÃ­culos + 4 pedestres)\n",
    "- **Teste**: 8 imagens (4 veÃ­culos + 4 pedestres)\n",
    "- **Total**: 80 imagens\n",
    "\n",
    "### **Classes Definidas:**\n",
    "- **Classe 0**: `vehicle` - Carros, motos, caminhÃµes\n",
    "- **Classe 1**: `pedestrian` - Pessoas caminhando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_config"
   },
   "outputs": [],
   "source": [
    "# ConfiguraÃ§Ã£o do dataset YAML\n",
    "dataset_yaml = {\n",
    "    'path': DATASET_PATH,\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': 2,  # number of classes\n",
    "    'names': ['vehicle', 'pedestrian']\n",
    "}\n",
    "\n",
    "# Salvando arquivo de configuraÃ§Ã£o\n",
    "with open(f'{DATASET_PATH}/dataset.yaml', 'w') as f:\n",
    "    yaml.dump(dataset_yaml, f)\n",
    "\n",
    "print("âœ… Arquivo dataset.yaml criado!")\n",
    "print("ðŸ“‹ ConfiguraÃ§Ã£o do dataset:")\n",
    "for key, value in dataset_yaml.items():\n",
    "    print(f"   {key}: {value}")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_sample_data"
   },
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o para baixar dataset de exemplo (COCO subset)\n",
    "def download_sample_dataset():\n",
    "    """\n",
    "    Baixa um subset do dataset COCO com veÃ­culos e pessoas\n",
    "    para demonstraÃ§Ã£o do projeto.\n",
    "    """\n",
    "    print("ðŸ“¥ Baixando dataset de exemplo...")\n",
    "    \n",
    "    # URLs de exemplo (substituir por dataset real)\n",
    "    sample_urls = {\n",
    "        'vehicles': [\n",
    "            'https://images.unsplash.com/photo-1549317661-bd32c8ce0db2?w=640',\n",
    "            'https://images.unsplash.com/photo-1552519507-da3b142c6e3d?w=640',\n",
    "            # Adicionar mais URLs conforme necessÃ¡rio\n",
    "        ],\n",
    "        'pedestrians': [\n",
    "            'https://images.unsplash.com/photo-1544005313-94ddf0286df2?w=640',\n",
    "            'https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?w=640',\n",
    "            # Adicionar mais URLs conforme necessÃ¡rio\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print("âš ï¸  IMPORTANTE: Para o projeto real, vocÃª deve:")\n",
    "    print("   1. Coletar 80 imagens reais (40 veÃ­culos + 40 pedestres)")\n",
    "    print("   2. Fazer upload para o Google Drive")\n",
    "    print("   3. Rotular usando Make Sense AI")\n",
    "    print("   4. Organizar nas pastas train/val/test")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Executar download\n",
    "download_sample_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "annotation_guide"
   },
   "source": [
    "## ðŸ·ï¸ **4. Guia de RotulaÃ§Ã£o com Make Sense AI**\n",
    "\n",
    "### **Processo de AnotaÃ§Ã£o:**\n",
    "\n",
    "1. **Acesse**: [Make Sense AI](https://www.makesense.ai/)\n",
    "2. **Upload das imagens**: Arraste suas 80 imagens\n",
    "3. **Configurar classes**:\n",
    "   - `vehicle` (ID: 0)\n",
    "   - `pedestrian` (ID: 1)\n",
    "4. **Desenhar bounding boxes** ao redor dos objetos\n",
    "5. **Exportar em formato YOLO**\n",
    "6. **Salvar labels** nas pastas correspondentes\n",
    "\n",
    "### **CritÃ©rios de Qualidade:**\n",
    "- âœ… **PrecisÃ£o**: Boxes ajustadas com margem de 2-3 pixels\n",
    "- âœ… **ConsistÃªncia**: Mesmo critÃ©rio para objetos similares\n",
    "- âœ… **Completude**: Todos os objetos relevantes anotados\n",
    "\n",
    "### **Formato YOLO (.txt):**\n",
    "```\n",
    "class_id center_x center_y width height\n",
    "```\n",
    "Exemplo: `0 0.5 0.5 0.3 0.4` (veÃ­culo no centro da imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_dataset"
   },
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o para verificar a estrutura do dataset\n",
    "def verify_dataset_structure(dataset_path):\n",
    "    """\n",
    "    Verifica se o dataset estÃ¡ corretamente estruturado\n",
    "    """\n",
    "    splits = ['train', 'val', 'test']\n",
    "    results = {}\n",
    "    \n",
    "    for split in splits:\n",
    "        images_path = f'{dataset_path}/{split}/images'\n",
    "        labels_path = f'{dataset_path}/{split}/labels'\n",
    "        \n",
    "        # Contar arquivos\n",
    "        images_count = len([f for f in os.listdir(images_path) if f.endswith(('.jpg', '.png', '.jpeg'))]) if os.path.exists(images_path) else 0\n",
    "        labels_count = len([f for f in os.listdir(labels_path) if f.endswith('.txt')]) if os.path.exists(labels_path) else 0\n",
    "        \n",
    "        results[split] = {\n",
    "            'images': images_count,\n",
    "            'labels': labels_count,\n",
    "            'match': images_count == labels_count\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Verificar estrutura atual\n",
    "structure = verify_dataset_structure(DATASET_PATH)\n",
    "\n",
    "print("ðŸ“Š Estrutura atual do dataset:")\n",
    "print("-" * 50)\n",
    "for split, data in structure.items():\n",
    "    status = "âœ…" if data['match'] and data['images'] > 0 else "âŒ"\n",
    "    print(f"{status} {split.upper()}: {data['images']} imagens, {data['labels']} labels")\n",
    "\n",
    "print("\nðŸ“ Para continuar, vocÃª precisa:")\n",
    "print("   1. Fazer upload das imagens para as pastas corretas")\n",
    "print("   2. Rotular no Make Sense AI")\n",
    "print("   3. Fazer upload dos arquivos .txt de labels")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_section"
   },
   "source": [
    "## ðŸš€ **5. Treinamento do Modelo YOLOv5**\n",
    "\n",
    "### **Experimento 1: 30 Ã‰pocas**\n",
    "\n",
    "Primeiro experimento com configuraÃ§Ã£o conservadora para estabelecer baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_30_epochs"
   },
   "outputs": [],
   "source": [
    "# ConfiguraÃ§Ãµes do Experimento 1\n",
    "EXPERIMENT_1 = {\n",
    "    'name': 'farmtech_30_epochs',\n",
    "    'epochs': 30,\n",
    "    'batch_size': 16,\n",
    "    'img_size': 640,\n",
    "    'learning_rate': 0.01,\n",
    "    'model': 'yolov5s.pt'  # Modelo pequeno para demonstraÃ§Ã£o\n",
    "}\n",
    "\n",
    "print("ðŸš€ Iniciando Experimento 1 - 30 Ã‰pocas")\n",
    "print("=" * 50)\n",
    "for key, value in EXPERIMENT_1.items():\n",
    "    print(f"ðŸ“‹ {key}: {value}")\n",
    "print("=" * 50)\n",
    "\n",
    "# Registrar tempo de inÃ­cio\n",
    "start_time_exp1 = time.time()\n",
    "\n",
    "# Comando de treinamento\n",
    "training_command_1 = f"""\n",
    "python train.py \n",
    "    --img {EXPERIMENT_1['img_size']} \n",
    "    --batch {EXPERIMENT_1['batch_size']} \n",
    "    --epochs {EXPERIMENT_1['epochs']} \n",
    "    --data {DATASET_PATH}/dataset.yaml \n",
    "    --weights {EXPERIMENT_1['model']} \n",
    "    --name {EXPERIMENT_1['name']} \n",
    "    --cache \n",
    "    --save-period 10\n",
    """"\n",
    "\n",
    "print("ðŸ’» Comando de treinamento:")\n",
    "print(training_command_1)\n",
    "\n",
    "# Executar treinamento (descomente quando dataset estiver pronto)\n",
    "# !{training_command_1}\n",
    "\n",
    "print("âš ï¸  Treinamento serÃ¡ executado quando o dataset estiver completo")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_60_epochs"
   },
   "source": [
    "### **Experimento 2: 60 Ã‰pocas**\n",
    "\n",
    "Segundo experimento com maior nÃºmero de Ã©pocas para avaliar convergÃªncia e possÃ­vel overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_60_epochs_code"
   },
   "outputs": [],
   "source": [
    "# ConfiguraÃ§Ãµes do Experimento 2\n",
    "EXPERIMENT_2 = {\n",
    "    'name': 'farmtech_60_epochs',\n",
    "    'epochs': 60,\n",
    "    'batch_size': 16,\n",
    "    'img_size': 640,\n",
    "    'learning_rate': 0.01,\n",
    "    'model': 'yolov5s.pt'\n",
    "}\n",
    "\n",
    "print("ðŸš€ Iniciando Experimento 2 - 60 Ã‰pocas")\n",
    "print("=" * 50)\n",
    "for key, value in EXPERIMENT_2.items():\n",
    "    print(f"ðŸ“‹ {key}: {value}")\n",
    "print("=" * 50)\n",
    "\n",
    "# Registrar tempo de inÃ­cio\n",
    "start_time_exp2 = time.time()\n",
    "\n",
    "# Comando de treinamento\n",
    "training_command_2 = f"""\n",
    "python train.py \n",
    "    --img {EXPERIMENT_2['img_size']} \n",
    "    --batch {EXPERIMENT_2['batch_size']} \n",
    "    --epochs {EXPERIMENT_2['epochs']} \n",
    "    --data {DATASET_PATH}/dataset.yaml \n",
    "    --weights {EXPERIMENT_2['model']} \n",
    "    --name {EXPERIMENT_2['name']} \n",
    "    --cache \n",
    "    --save-period 15\n",
    """"\n",
    "\n",
    "print("ðŸ’» Comando de treinamento:")\n",
    "print(training_command_2)\n",
    "\n",
    "# Executar treinamento (descomente quando dataset estiver pronto)\n",
    "# !{training_command_2}\n",
    "\n",
    "print("âš ï¸  Treinamento serÃ¡ executado quando o dataset estiver completo")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis_section"
   },
   "source": [
    "## ðŸ“Š **6. AnÃ¡lise Comparativa dos Resultados**\n",
    "\n",
    "AnÃ¡lise detalhada dos dois experimentos com foco em mÃ©tricas de performance e insights acadÃªmicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results_analysis"
   },
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o para analisar resultados do treinamento\n",
    "def analyze_training_results(exp_name):\n",
    "    """\n",
    "    Analisa os resultados de um experimento de treinamento\n",
    "    """\n",
    "    results_path = f'runs/train/{exp_name}'\n",
    "    \n",
    "    if not os.path.exists(results_path):\n",
    "        print(f"âŒ Resultados nÃ£o encontrados para {exp_name}")\n",
    "        return None\n",
    "    \n",
    "    # Carregar resultados CSV\n",
    "    try:\n",
    "        results_df = pd.read_csv(f'{results_path}/results.csv')\n",
    "        results_df.columns = results_df.columns.str.strip()  # Remove espaÃ§os\n",
    "        \n",
    "        # MÃ©tricas finais\n",
    "        final_metrics = {\n",
    "            'mAP_0.5': results_df['metrics/mAP_0.5'].iloc[-1],\n",
    "            'mAP_0.5:0.95': results_df['metrics/mAP_0.5:0.95'].iloc[-1],\n",
    "            'precision': results_df['metrics/precision'].iloc[-1],\n",
    "            'recall': results_df['metrics/recall'].iloc[-1],\n",
    "            'train_loss': results_df['train/box_loss'].iloc[-1],\n",
    "            'val_loss': results_df['val/box_loss'].iloc[-1]\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'dataframe': results_df,\n",
    "            'metrics': final_metrics,\n",
    "            'path': results_path\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f"âŒ Erro ao carregar resultados: {e}")\n",
    "        return None\n",
    "\n",
    "# FunÃ§Ã£o para criar visualizaÃ§Ãµes comparativas\n",
    "def create_comparison_plots(results_30, results_60):\n",
    "    """\n",
    "    Cria grÃ¡ficos comparativos entre os dois experimentos\n",
    "    """\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('ðŸ“Š AnÃ¡lise Comparativa: 30 vs 60 Ã‰pocas', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # GrÃ¡fico 1: mAP ao longo das Ã©pocas\n",
    "    axes[0, 0].plot(results_30['dataframe']['epoch'], results_30['dataframe']['metrics/mAP_0.5'], \n",
    "                   label='30 Ã‰pocas', linewidth=2, color='blue')\n",
    "    axes[0, 0].plot(results_60['dataframe']['epoch'], results_60['dataframe']['metrics/mAP_0.5'], \n",
    "                   label='60 Ã‰pocas', linewidth=2, color='red')\n",
    "    axes[0, 0].set_title('mAP@0.5 por Ã‰poca')\n",
    "    axes[0, 0].set_xlabel('Ã‰poca')\n",
    "    axes[0, 0].set_ylabel('mAP@0.5')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # GrÃ¡fico 2: Loss de treinamento\n",
    "    axes[0, 1].plot(results_30['dataframe']['epoch'], results_30['dataframe']['train/box_loss'], \n",
    "                   label='30 Ã‰pocas', linewidth=2, color='blue')\n",
    "    axes[0, 1].plot(results_60['dataframe']['epoch'], results_60['dataframe']['train/box_loss'], \n",
    "                   label='60 Ã‰pocas', linewidth=2, color='red')\n",
    "    axes[0, 1].set_title('Loss de Treinamento')\n",
    "    axes[0, 1].set_xlabel('Ã‰poca')\n",
    "    axes[0, 1].set_ylabel('Box Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # GrÃ¡fico 3: Precision vs Recall\n",
    "    axes[1, 0].plot(results_30['dataframe']['epoch'], results_30['dataframe']['metrics/precision'], \n",
    "                   label='Precision (30 Ã©pocas)', linewidth=2, color='blue', linestyle='-')\n",
    "    axes[1, 0].plot(results_30['dataframe']['epoch'], results_30['dataframe']['metrics/recall'], \n",
    "                   label='Recall (30 Ã©pocas)', linewidth=2, color='blue', linestyle='--')\n",
    "    axes[1, 0].plot(results_60['dataframe']['epoch'], results_60['dataframe']['metrics/precision'], \n",
    "                   label='Precision (60 Ã©pocas)', linewidth=2, color='red', linestyle='-')\n",
    "    axes[1, 0].plot(results_60['dataframe']['epoch'], results_60['dataframe']['metrics/recall'], \n",
    "                   label='Recall (60 Ã©pocas)', linewidth=2, color='red', linestyle='--')\n",
    "    axes[1, 0].set_title('Precision vs Recall')\n",
    "    axes[1, 0].set_xlabel('Ã‰poca')\n",
    "    axes[1, 0].set_ylabel('Valor')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # GrÃ¡fico 4: ComparaÃ§Ã£o de mÃ©tricas finais\n",
    "    metrics_names = ['mAP_0.5', 'mAP_0.5:0.95', 'precision', 'recall']\n",
    "    values_30 = [results_30['metrics'][m] for m in metrics_names]\n",
    "    values_60 = [results_60['metrics'][m] for m in metrics_names]\n",
    "    \n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 1].bar(x - width/2, values_30, width, label='30 Ã‰pocas', color='blue', alpha=0.7)\n",
    "    axes[1, 1].bar(x + width/2, values_60, width, label='60 Ã‰pocas', color='red', alpha=0.7)\n",
    "    axes[1, 1].set_title('ComparaÃ§Ã£o de MÃ©tricas Finais')\n",
    "    axes[1, 1].set_xlabel('MÃ©tricas')\n",
    "    axes[1, 1].set_ylabel('Valor')\n",
    "    axes[1, 1].set_xticks(x)\n",
    "    axes[1, 1].set_xticklabels(metrics_names, rotation=45)\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print("ï¿½ï¿½ FunÃ§Ãµes de anÃ¡lise criadas!")\n",
    "print("âš ï¸  Execute apÃ³s completar os treinamentos para ver os resultados")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "testing_section"
   },
   "source": [
    "## ðŸ§ª **7. ValidaÃ§Ã£o e Testes**\n",
    "\n",
    "AvaliaÃ§Ã£o dos modelos treinados no conjunto de teste e anÃ¡lise de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_testing"
   },
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o para testar modelo treinado\n",
    "def test_trained_model(model_path, test_data_path):\n",
    "    """\n",
    "    Testa o modelo treinado no conjunto de teste\n",
    "    """\n",
    "    print(f"ðŸ§ª Testando modelo: {model_path}")\n",
    "    \n",
    "    # Comando de teste\n",
    "    test_command = f"""\n",
    "    python val.py \n",
    "        --weights {model_path} \n",
    "        --data {test_data_path} \n",
    "        --img 640 \n",
    "        --save-txt \n",
    "        --save-conf\n",
    "    """\n",
    "    \n",
    "    print("ðŸ’» Comando de teste:")\n",
    "    print(test_command)\n",
    "    \n",
    "    # Executar teste (descomente quando modelo estiver treinado)\n",
    "    # !{test_command}\n",
    "    \n",
    "    return test_command\n",
    "\n",
    "# FunÃ§Ã£o para inferÃªncia em imagens especÃ­ficas\n",
    "def run_inference_examples(model_path, images_path, output_path):\n",
    "    """\n",
    "    Executa inferÃªncia em imagens de exemplo\n",
    "    """\n",
    "    print(f"ðŸ” Executando inferÃªncia com modelo: {model_path}")\n",
    "    \n",
    "    inference_command = f"""\n",
    "    python detect.py \n",
    "        --weights {model_path} \n",
    "        --source {images_path} \n",
    "        --img 640 \n",
    "        --conf 0.25 \n",
    "        --save-txt \n",
    "        --save-conf \n",
    "        --project {output_path}\n",
    "    """\n",
    "    \n",
    "    print("ðŸ’» Comando de inferÃªncia:")\n",
    "    print(inference_command)\n",
    "    \n",
    "    return inference_command\n",
    "\n",
    "# Preparar testes para ambos os modelos\n",
    "models_to_test = [\n",
    "    {\n",
    "        'name': '30 Ã‰pocas',\n",
    "        'path': 'runs/train/farmtech_30_epochs/weights/best.pt',\n",
    "        'output': f'{RESULTS_PATH}/experiment_30_epochs/test_results'\n",
    "    },\n",
    "    {\n",
    "        'name': '60 Ã‰pocas', \n",
    "        'path': 'runs/train/farmtech_60_epochs/weights/best.pt',\n",
    "        'output': f'{RESULTS_PATH}/experiment_60_epochs/test_results'\n",
    "    }\n",
    "]\n",
    "\n",
    "print("ðŸ§ª Modelos preparados para teste:")\n",
    "for model in models_to_test:\n",
    "    print(f"   ðŸ“‹ {model['name']}: {model['path']}")\n",
    "\n",
    "print("\nâš ï¸  Execute os testes apÃ³s completar os treinamentos")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results_visualization"
   },
   "source": [
    "## ðŸ“ˆ **8. VisualizaÃ§Ã£o de Resultados**\n",
    "\n",
    "CriaÃ§Ã£o de visualizaÃ§Ãµes para demonstrar a eficÃ¡cia dos modelos treinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_visualizations"
   },
   "outputs": [],
   "source": [
    "# FunÃ§Ã£o para criar tabela de comparaÃ§Ã£o final\n",
    "def create_final_comparison_table(results_30, results_60, training_times):\n",
    "    """\n",
    "    Cria tabela comparativa final dos experimentos\n",
    "    """\n",
    "    comparison_data = {\n",
    "        'MÃ©trica': ['Ã‰pocas', 'mAP@0.5', 'mAP@0.5:0.95', 'Precision', 'Recall', \n",
    "                   'Tempo de Treinamento (min)', 'Overfitting Risk'],\n",
    "        'Experimento 1 (30 Ã©pocas)': [\n",
    "            30,\n",
    "            f"{results_30['metrics']['mAP_0.5']:.3f}" if results_30 else 'TBD',\n",
    "            f"{results_30['metrics']['mAP_0.5:0.95']:.3f}" if results_30 else 'TBD',\n",
    "            f"{results_30['metrics']['precision']:.3f}" if results_30 else 'TBD',\n",
    "            f"{results_30['metrics']['recall']:.3f}" if results_30 else 'TBD',\n",
    "            f"{training_times['exp1']:.1f}" if 'exp1' in training_times else 'TBD',\n",
    "            'Baixo'\n",
    "        ],\n",
    "        'Experimento 2 (60 Ã©pocas)': [\n",
    "            60,\n",
    "            f"{results_60['metrics']['mAP_0.5']:.3f}" if results_60 else 'TBD',\n",
    "            f"{results_60['metrics']['mAP_0.5:0.95']:.3f}" if results_60 else 'TBD',\n",
    "            f"{results_60['metrics']['precision']:.3f}" if results_60 else 'TBD',\n",
    "            f"{results_60['metrics']['recall']:.3f}" if results_60 else 'TBD',\n",
    "            f"{training_times['exp2']:.1f}" if 'exp2' in training_times else 'TBD',\n",
    "            'MÃ©dio'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Estilizar tabela\n",
    "    styled_table = df_comparison.style.set_properties(**{\n",
    "        'background-color': '#f0f0f0',\n",
    "        'color': 'black',\n",
    "        'border-color': 'white'\n",
    "    })\n",
    "    \n",
    "    return df_comparison, styled_table\n",
    "\n",
    "# FunÃ§Ã£o para mostrar imagens de resultado\n",
    "def display_detection_results(results_path, num_images=4):\n",
    "    """\n",
    "    Exibe resultados de detecÃ§Ã£o em imagens de teste\n",
    "    """\n",
    "    if not os.path.exists(results_path):\n",
    "        print(f"âŒ Pasta de resultados nÃ£o encontrada: {results_path}")\n",
    "        return\n",
    "    \n",
    "    # Buscar imagens de resultado\n",
    "    result_images = [f for f in os.listdir(results_path) if f.endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    if not result_images:\n",
    "        print("âŒ Nenhuma imagem de resultado encontrada")\n",
    "        return\n",
    "    \n",
    "    # Mostrar primeiras imagens\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('ðŸŽ¯ Resultados de DetecÃ§Ã£o - Imagens Processadas', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, img_name in enumerate(result_images[:num_images]):\n",
    "        if i >= 4:  # MÃ¡ximo 4 imagens\n",
    "            break\n",
    "            \n",
    "        img_path = os.path.join(results_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        \n",
    "        axes[row, col].imshow(img_rgb)\n",
    "        axes[row, col].set_title(f'DetecÃ§Ã£o: {img_name}')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    # Remover subplots vazios\n",
    "    for i in range(len(result_images), 4):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        axes[row, col].remove()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print("ðŸ“Š FunÃ§Ãµes de visualizaÃ§Ã£o criadas!")\n",
    "print("ðŸŽ¯ Use apÃ³s completar os experimentos para gerar relatÃ³rios visuais")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusions"
   },
   "source": [
    "## ðŸŽ¯ **9. ConclusÃµes e Insights AcadÃªmicos**\n",
    "\n",
    "### **AnÃ¡lise Comparativa Esperada:**\n",
    "\n",
    "#### **HipÃ³teses a Serem Validadas:**\n",
    "\n",
    
