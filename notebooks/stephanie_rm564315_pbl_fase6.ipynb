{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üéØ FarmTech Vision Solutions - Sistema de Detec√ß√£o com YOLOv5\n",
    "\n",
    "**Projeto:** Fase 6 - Redes Neurais e Vis√£o Computacional  \n",
    "**Aluna:** Stephanie  \n",
    "**RM:** 564315  \n",
    "**Curso:** Intelig√™ncia Artificial - FIAP  \n",
    "**Data:** 2024  \n",
    "\n",
    "---\n",
    "\n",
    "## üìã **Objetivos do Projeto**\n",
    "\n",
    "Este notebook implementa um sistema completo de vis√£o computacional usando **YOLOv5** para detec√ß√£o de:\n",
    "- **üöó Ve√≠culos** (carros, motos, caminh√µes)\n",
    "- **üö∂ Pedestres** (pessoas caminhando)\n",
    "\n",
    "### **Experimentos Planejados:**\n",
    "1. **Treinamento com 30 √©pocas**\n",
    "2. **Treinamento com 60 √©pocas**\n",
    "3. **An√°lise comparativa de performance**\n",
    "\n",
    "### **M√©tricas de Avalia√ß√£o:**\n",
    "- Precision, Recall, F1-Score\n",
    "- mAP@0.5 e mAP@0.5:0.95\n",
    "- Tempo de treinamento e infer√™ncia\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "theory"
   },
   "source": [
    "## üß† **Fundamenta√ß√£o Te√≥rica**\n",
    "\n",
    "### **YOLO (You Only Look Once)**\n",
    "\n",
    "O YOLO revolucionou a detec√ß√£o de objetos ao tratar o problema como uma **√∫nica regress√£o end-to-end**, diferente dos m√©todos tradicionais de duas etapas.\n",
    "\n",
    "#### **Principais Inova√ß√µes:**\n",
    "\n",
    "1. **Arquitetura Unificada**: Uma √∫nica rede neural prediz simultaneamente:\n",
    "   - Coordenadas das bounding boxes\n",
    "   - Probabilidades de classe\n",
    "   - Scores de confian√ßa\n",
    "\n",
    "2. **Processamento Global**: Analisa a imagem inteira de uma vez, capturando contexto global\n",
    "\n",
    "3. **Velocidade**: Capaz de processar imagens em tempo real (>30 FPS)\n",
    "\n",
    "#### **YOLOv5 - Arquitetura Detalhada:**\n",
    "\n",
    "- **Backbone**: CSPDarknet53 para extra√ß√£o de features hier√°rquicas\n",
    "- **Neck**: PANet (Path Aggregation Network) para fus√£o multi-escala\n",
    "- **Head**: Tr√™s camadas de detec√ß√£o para diferentes escalas de objetos\n",
    "\n",
    "#### **Fun√ß√£o de Perda Multi-objetivo:**\n",
    "\n",
    "```\n",
    "Loss_total = Œª_box √ó Loss_box + Œª_obj √ó Loss_obj + Œª_cls √ó Loss_cls\n",
    "```\n",
    "\n",
    "Onde:\n",
    "- **Loss_box**: Erro de localiza√ß√£o (coordenadas)\n",
    "- **Loss_obj**: Erro de objetividade (confian√ßa)\n",
    "- **Loss_cls**: Erro de classifica√ß√£o\n",
    "\n",
    "### **Refer√™ncias Acad√™micas:**\n",
    "\n",
    "1. **Redmon, J., et al. (2016)**. "You Only Look Once: Unified, Real-Time Object Detection." *CVPR*.\n",
    "2. **Bochkovskiy, A., et al. (2020)**. "YOLOv4: Optimal Speed and Accuracy of Object Detection." *arXiv*.\n",
    "3. **Jocher, G., et al. (2022)**. "ultralytics/yolov5: v7.0 - YOLOv5 SOTA Realtime Instance Segmentation."\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## ‚öôÔ∏è **1. Configura√ß√£o do Ambiente**\n",
    "\n",
    "Instala√ß√£o das depend√™ncias necess√°rias para o projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_dependencies"
   },
   "outputs": [],
   "source": [
    "# Instala√ß√£o das bibliotecas principais\n",
    "!pip install ultralytics\n",
    "!pip install roboflow\n",
    "!pip install opencv-python\n",
    "!pip install matplotlib seaborn plotly\n",
    "!pip install pandas numpy\n",
    "\n",
    "# Clonando o reposit√≥rio YOLOv5 oficial\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "print("‚úÖ Ambiente configurado com sucesso!")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Importa√ß√µes necess√°rias\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import os\n",
    "import yaml\n",
    "import time\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from google.colab import drive, files\n",
    "import zipfile\n",
    "import requests\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette("husl")\n",
    "\n",
    "# Verifica√ß√£o do ambiente\n",
    "print(f"üî• PyTorch Version: {torch.__version__}")\n",
    "print(f"üñ•Ô∏è  CUDA Available: {torch.cuda.is_available()}")\n",
    "print(f"üéØ Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}")\n",
    "print(f"üìä OpenCV Version: {cv2.__version__}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drive_setup"
   },
   "source": [
    "## üíæ **2. Configura√ß√£o do Google Drive**\n",
    "\n",
    "Conectando ao Google Drive para acessar o dataset e salvar resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Montando o Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Definindo caminhos do projeto\n",
    "PROJECT_PATH = '/content/drive/MyDrive/FarmTech_YOLO_Project'\n",
    "DATASET_PATH = f'{PROJECT_PATH}/dataset'\n",
    "RESULTS_PATH = f'{PROJECT_PATH}/results'\n",
    "\n",
    "# Criando estrutura de pastas\n",
    "os.makedirs(f'{DATASET_PATH}/train/images', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_PATH}/train/labels', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_PATH}/val/images', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_PATH}/val/labels', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_PATH}/test/images', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_PATH}/test/labels', exist_ok=True)\n",
    "os.makedirs(f'{RESULTS_PATH}/experiment_30_epochs', exist_ok=True)\n",
    "os.makedirs(f'{RESULTS_PATH}/experiment_60_epochs', exist_ok=True)\n",
    "\n",
    "print("üìÅ Estrutura de pastas criada com sucesso!")\n",
    "print(f"üìÇ Dataset Path: {DATASET_PATH}")\n",
    "print(f"üìä Results Path: {RESULTS_PATH}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset_section"
   },
   "source": [
    "## üìä **3. Prepara√ß√£o do Dataset**\n",
    "\n",
    "### **Dataset: Ve√≠culos vs Pedestres**\n",
    "\n",
    "**Distribui√ß√£o planejada:**\n",
    "- **Treinamento**: 64 imagens (32 ve√≠culos + 32 pedestres)\n",
    "- **Valida√ß√£o**: 8 imagens (4 ve√≠culos + 4 pedestres)\n",
    "- **Teste**: 8 imagens (4 ve√≠culos + 4 pedestres)\n",
    "- **Total**: 80 imagens\n",
    "\n",
    "### **Classes Definidas:**\n",
    "- **Classe 0**: `vehicle` - Carros, motos, caminh√µes\n",
    "- **Classe 1**: `pedestrian` - Pessoas caminhando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_config"
   },
   "outputs": [],
   "source": [
    "# Configura√ß√£o do dataset YAML\n",
    "dataset_yaml = {\n",
    "    'path': DATASET_PATH,\n",
    "    'train': 'train/images',\n",
    "    'val': 'val/images',\n",
    "    'test': 'test/images',\n",
    "    'nc': 2,  # number of classes\n",
    "    'names': ['vehicle', 'pedestrian']\n",
    "}\n",
    "\n",
    "# Salvando arquivo de configura√ß√£o\n",
    "with open(f'{DATASET_PATH}/dataset.yaml', 'w') as f:\n",
    "    yaml.dump(dataset_yaml, f)\n",
    "\n",
    "print("‚úÖ Arquivo dataset.yaml criado!")\n",
    "print("üìã Configura√ß√£o do dataset:")\n",
    "for key, value in dataset_yaml.items():\n",
    "    print(f"   {key}: {value}")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_sample_data"
   },
   "outputs": [],
   "source": [
    "# Fun√ß√£o para baixar dataset de exemplo (COCO subset)\n",
    "def download_sample_dataset():\n",
    "    """\n",
    "    Baixa um subset do dataset COCO com ve√≠culos e pessoas\n",
    "    para demonstra√ß√£o do projeto.\n",
    "    """\n",
    "    print("üì• Baixando dataset de exemplo...")\n",
    "    \n",
    "    # URLs de exemplo (substituir por dataset real)\n",
    "    sample_urls = {\n",
    "        'vehicles': [\n",
    "            'https://images.unsplash.com/photo-1549317661-bd32c8ce0db2?w=640',\n",
    "            'https://images.unsplash.com/photo-1552519507-da3b142c6e3d?w=640',\n",
    "            # Adicionar mais URLs conforme necess√°rio\n",
    "        ],\n",
    "        'pedestrians': [\n",
    "            'https://images.unsplash.com/photo-1544005313-94ddf0286df2?w=640',\n",
    "            'https://images.unsplash.com/photo-1507003211169-0a1dd7228f2d?w=640',\n",
    "            # Adicionar mais URLs conforme necess√°rio\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print("‚ö†Ô∏è  IMPORTANTE: Para o projeto real, voc√™ deve:")\n",
    "    print("   1. Coletar 80 imagens reais (40 ve√≠culos + 40 pedestres)")\n",
    "    print("   2. Fazer upload para o Google Drive")\n",
    "    print("   3. Rotular usando Make Sense AI")\n",
    "    print("   4. Organizar nas pastas train/val/test")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Executar download\n",
    "download_sample_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "annotation_guide"
   },
   "source": [
    "## üè∑Ô∏è **4. Guia de Rotula√ß√£o com Make Sense AI**\n",
    "\n",
    "### **Processo de Anota√ß√£o:**\n",
    "\n",
    "1. **Acesse**: [Make Sense AI](https://www.makesense.ai/)\n",
    "2. **Upload das imagens**: Arraste suas 80 imagens\n",
    "3. **Configurar classes**:\n",
    "   - `vehicle` (ID: 0)\n",
    "   - `pedestrian` (ID: 1)\n",
    "4. **Desenhar bounding boxes** ao redor dos objetos\n",
    "5. **Exportar em formato YOLO**\n",
    "6. **Salvar labels** nas pastas correspondentes\n",
    "\n",
    "### **Crit√©rios de Qualidade:**\n",
    "- ‚úÖ **Precis√£o**: Boxes ajustadas com margem de 2-3 pixels\n",
    "- ‚úÖ **Consist√™ncia**: Mesmo crit√©rio para objetos similares\n",
    "- ‚úÖ **Completude**: Todos os objetos relevantes anotados\n",
    "\n",
    "### **Formato YOLO (.txt):**\n",
    "```\n",
    "class_id center_x center_y width height\n",
    "```\n",
    "Exemplo: `0 0.5 0.5 0.3 0.4` (ve√≠culo no centro da imagem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "verify_dataset"
   },
   "outputs": [],
   "source": [
    "# Fun√ß√£o para verificar a estrutura do dataset\n",
    "def verify_dataset_structure(dataset_path):\n",
    "    """\n",
    "    Verifica se o dataset est√° corretamente estruturado\n",
    "    """\n",
    "    splits = ['train', 'val', 'test']\n",
    "    results = {}\n",
    "    \n",
    "    for split in splits:\n",
    "        images_path = f'{dataset_path}/{split}/images'\n",
    "        labels_path = f'{dataset_path}/{split}/labels'\n",
    "        \n",
    "        # Contar arquivos\n",
    "        images_count = len([f for f in os.listdir(images_path) if f.endswith(('.jpg', '.png', '.jpeg'))]) if os.path.exists(images_path) else 0\n",
    "        labels_count = len([f for f in os.listdir(labels_path) if f.endswith('.txt')]) if os.path.exists(labels_path) else 0\n",
    "        \n",
    "        results[split] = {\n",
    "            'images': images_count,\n",
    "            'labels': labels_count,\n",
    "            'match': images_count == labels_count\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Verificar estrutura atual\n",
    "structure = verify_dataset_structure(DATASET_PATH)\n",
    "\n",
    "print("üìä Estrutura atual do dataset:")\n",
    "print("-" * 50)\n",
    "for split, data in structure.items():\n",
    "    status = "‚úÖ" if data['match'] and data['images'] > 0 else "‚ùå"\n",
    "    print(f"{status} {split.upper()}: {data['images']} imagens, {data['labels']} labels")\n",
    "\n",
    "print("\nüìù Para continuar, voc√™ precisa:")\n",
    "print("   1. Fazer upload das imagens para as pastas corretas")\n",
    "print("   2. Rotular no Make Sense AI")\n",
    "print("   3. Fazer upload dos arquivos .txt de labels")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_section"
   },
   "source": [
    "## üöÄ **5. Treinamento do Modelo YOLOv5**\n",
    "\n",
    "### **Experimento 1: 30 √âpocas**\n",
    "\n",
    "Primeiro experimento com configura√ß√£o conservadora para estabelecer baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_30_epochs"
   },
   "outputs": [],
   "source": [
    "# Configura√ß√µes do Experimento 1\n",
    "EXPERIMENT_1 = {\n",
    "    'name': 'farmtech_30_epochs',\n",
    "    'epochs': 30,\n",
    "    'batch_size': 16,\n",
    "    'img_size': 640,\n",
    "    'learning_rate': 0.01,\n",
    "    'model': 'yolov5s.pt'  # Modelo pequeno para demonstra√ß√£o\n",
    "}\n",
    "\n",
    "print("üöÄ Iniciando Experimento 1 - 30 √âpocas")\n",
    "print("=" * 50)\n",
    "for key, value in EXPERIMENT_1.items():\n",
    "    print(f"üìã {key}: {value}")\n",
    "print("=" * 50)\n",
    "\n",
    "# Registrar tempo de in√≠cio\n",
    "start_time_exp1 = time.time()\n",
    "\n",
    "# Comando de treinamento\n",
    "training_command_1 = f"""\n",
    "python train.py \n",
    "    --img {EXPERIMENT_1['img_size']} \n",
    "    --batch {EXPERIMENT_1['batch_size']} \n",
    "    --epochs {EXPERIMENT_1['epochs']} \n",
    "    --data {DATASET_PATH}/dataset.yaml \n",
    "    --weights {EXPERIMENT_1['model']} \n",
    "    --name {EXPERIMENT_1['name']} \n",
    "    --cache \n",
    "    --save-period 10\n",
    """"\n",
    "\n",
    "print("üíª Comando de treinamento:")\n",
    "print(training_command_1)\n",
    "\n",
    "# Executar treinamento (descomente quando dataset estiver pronto)\n",
    "# !{training_command_1}\n",
    "\n",
    "print("‚ö†Ô∏è  Treinamento ser√° executado quando o dataset estiver completo")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training_60_epochs"
   },
   "source": [
    "### **Experimento 2: 60 √âpocas**\n",
    "\n",
    "Segundo experimento com maior n√∫mero de √©pocas para avaliar converg√™ncia e poss√≠vel overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_60_epochs_code"
   },
   "outputs": [],
   "source": [
    "# Configura√ß√µes do Experimento 2\n",
    "EXPERIMENT_2 = {\n",
    "    'name': 'farmtech_60_epochs',\n",
    "    'epochs': 60,\n",
    "    'batch_size': 16,\n",
    "    'img_size': 640,\n",
    "    'learning_rate': 0.01,\n",
    "    'model': 'yolov5s.pt'\n",
    "}\n",
    "\n",
    "print("üöÄ Iniciando Experimento 2 - 60 √âpocas")\n",
    "print("=" * 50)\n",
    "for key, value in EXPERIMENT_2.items():\n",
    "    print(f"üìã {key}: {value}")\n",
    "print("=" * 50)\n",
    "\n",
    "# Registrar tempo de in√≠cio\n",
    "start_time_exp2 = time.time()\n",
    "\n",
    "# Comando de treinamento\n",
    "training_command_2 = f"""\n",
    "python train.py \n",
    "    --img {EXPERIMENT_2['img_size']} \n",
    "    --batch {EXPERIMENT_2['batch_size']} \n",
    "    --epochs {EXPERIMENT_2['epochs']} \n",
    "    --data {DATASET_PATH}/dataset.yaml \n",
    "    --weights {EXPERIMENT_2['model']} \n",
    "    --name {EXPERIMENT_2['name']} \n",
    "    --cache \n",
    "    --save-period 15\n",
    """"\n",
    "\n",
    "print("üíª Comando de treinamento:")\n",
    "print(training_command_2)\n",
    "\n",
    "# Executar treinamento (descomente quando dataset estiver pronto)\n",
    "# !{training_command_2}\n",
    "\n",
    "print("‚ö†Ô∏è  Treinamento ser√° executado quando o dataset estiver completo")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "analysis_section"
   },
   "source": [
    "## üìä **6. An√°lise Comparativa dos Resultados**\n",
    "\n",
    "An√°lise detalhada dos dois experimentos com foco em m√©tricas de performance e insights acad√™micos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "results_analysis"
   },
   "outputs": [],
   "source": [
    "# Fun√ß√£o para analisar resultados do treinamento\n",
    "def analyze_training_results(exp_name):\n",
    "    """\n",
    "    Analisa os resultados de um experimento de treinamento\n",
    "    """\n",
    "    results_path = f'runs/train/{exp_name}'\n",
    "    \n",
    "    if not os.path.exists(results_path):\n",
    "        print(f"‚ùå Resultados n√£o encontrados para {exp_name}")\n",
    "        return None\n",
    "    \n",
    "    # Carregar resultados CSV\n",
    "    try:\n",
    "        results_df = pd.read_csv(f'{results_path}/results.csv')\n",
    "        results_df.columns = results_df.columns.str.strip()  # Remove espa√ßos\n",
    "        \n",
    "        # M√©tricas finais\n",
    "        final_metrics = {\n",
    "            'mAP_0.5': results_df['metrics/mAP_0.5'].iloc[-1],\n",
    "            'mAP_0.5:0.95': results_df['metrics/mAP_0.5:0.95'].iloc[-1],\n",
    "            'precision': results_df['metrics/precision'].iloc[-1],\n",
    "            'recall': results_df['metrics/recall'].iloc[-1],\n",
    "            'train_loss': results_df['train/box_loss'].iloc[-1],\n",
    "            'val_loss': results_df['val/box_loss'].iloc[-1]\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'dataframe': results_df,\n",
    "            'metrics': final_metrics,\n",
    "            'path': results_path\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f"‚ùå Erro ao carregar resultados: {e}")\n",
    "        return None\n",
    "\n",
    "# Fun√ß√£o para criar visualiza√ß√µes comparativas\n",
    "def create_comparison_plots(results_30, results_60):\n",
    "    """\n",
    "    Cria gr√°ficos comparativos entre os dois experimentos\n",
    "    """\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('üìä An√°lise Comparativa: 30 vs 60 √âpocas', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Gr√°fico 1: mAP ao longo das √©pocas\n",
    "    axes[0, 0].plot(results_30['dataframe']['epoch'], results_30['dataframe']['metrics/mAP_0.5'], \n",
    "                   label='30 √âpocas', linewidth=2, color='blue')\n",
    "    axes[0, 0].plot(results_60['dataframe']['epoch'], results_60['dataframe']['metrics/mAP_0.5'], \n",
    "                   label='60 √âpocas', linewidth=2, color='red')\n",
    "    axes[0, 0].set_title('mAP@0.5 por √âpoca')\n",
    "    axes[0, 0].set_xlabel('√âpoca')\n",
    "    axes[0, 0].set_ylabel('mAP@0.5')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gr√°fico 2: Loss de treinamento\n",
    "    axes[0, 1].plot(results_30['dataframe']['epoch'], results_30['dataframe']['train/box_loss'], \n",
    "                   label='30 √âpocas', linewidth=2, color='blue')\n",
    "    axes[0, 1].plot(results_60['dataframe']['epoch'], results_60['dataframe']['train/box_loss'], \n",
    "                   label='60 √âpocas', linewidth=2, color='red')\n",
    "    axes[0, 1].set_title('Loss de Treinamento')\n",
    "    axes[0, 1].set_xlabel('√âpoca')\n",
    "    axes[0, 1].set_ylabel('Box Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gr√°fico 3: Precision vs Recall\n",
    "    axes[1, 0].plot(results_30['dataframe']['epoch'], results_30['dataframe']['metrics/precision'], \n",
    "                   label='Precision (30 √©pocas)', linewidth=2, color='blue', linestyle='-')\n",
    "    axes[1, 0].plot(results_30['dataframe']['epoch'], results_30['dataframe']['metrics/recall'], \n",
    "                   label='Recall (30 √©pocas)', linewidth=2, color='blue', linestyle='--')\n",
    "    axes[1, 0].plot(results_60['dataframe']['epoch'], results_60['dataframe']['metrics/precision'], \n",
    "                   label='Precision (60 √©pocas)', linewidth=2, color='red', linestyle='-')\n",
    "    axes[1, 0].plot(results_60['dataframe']['epoch'], results_60['dataframe']['metrics/recall'], \n",
    "                   label='Recall (60 √©pocas)', linewidth=2, color='red', linestyle='--')\n",
    "    axes[1, 0].set_title('Precision vs Recall')\n",
    "    axes[1, 0].set_xlabel('√âpoca')\n",
    "    axes[1, 0].set_ylabel('Valor')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Gr√°fico 4: Compara√ß√£o de m√©tricas finais\n",
    "    metrics_names = ['mAP_0.5', 'mAP_0.5:0.95', 'precision', 'recall']\n",
    "    values_30 = [results_30['metrics'][m] for m in metrics_names]\n",
    "    values_60 = [results_60['metrics'][m] for m in metrics_names]\n",
    "    \n",
    "    x = np.arange(len(metrics_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 1].bar(x - width/2, values_30, width, label='30 √âpocas', color='blue', alpha=0.7)\n",
    "    axes[1, 1].bar(x + width/2, values_60, width, label='60 √âpocas', color='red', alpha=0.7)\n",
    "    axes[1, 1].set_title('Compara√ß√£o de M√©tricas Finais')\n",
    "    axes[1, 1].set_xlabel('M√©tricas')\n",
    "    axes[1, 1].set_ylabel('Valor')\n",
    "    axes[1, 1].set_xticks(x)\n",
    "    axes[1, 1].set_xticklabels(metrics_names, rotation=45)\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print("ÔøΩÔøΩ Fun√ß√µes de an√°lise criadas!")\n",
    "print("‚ö†Ô∏è  Execute ap√≥s completar os treinamentos para ver os resultados")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "testing_section"
   },
   "source": [
    "## üß™ **7. Valida√ß√£o e Testes**\n",
    "\n",
    "Avalia√ß√£o dos modelos treinados no conjunto de teste e an√°lise de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_testing"
   },
   "outputs": [],
   "source": [
    "# Fun√ß√£o para testar modelo treinado\n",
    "def test_trained_model(model_path, test_data_path):\n",
    "    """\n",
    "    Testa o modelo treinado no conjunto de teste\n",
    "    """\n",
    "    print(f"üß™ Testando modelo: {model_path}")\n",
    "    \n",
    "    # Comando de teste\n",
    "    test_command = f"""\n",
    "    python val.py \n",
    "        --weights {model_path} \n",
    "        --data {test_data_path} \n",
    "        --img 640 \n",
    "        --save-txt \n",
    "        --save-conf\n",
    "    """\n",
    "    \n",
    "    print("üíª Comando de teste:")\n",
    "    print(test_command)\n",
    "    \n",
    "    # Executar teste (descomente quando modelo estiver treinado)\n",
    "    # !{test_command}\n",
    "    \n",
    "    return test_command\n",
    "\n",
    "# Fun√ß√£o para infer√™ncia em imagens espec√≠ficas\n",
    "def run_inference_examples(model_path, images_path, output_path):\n",
    "    """\n",
    "    Executa infer√™ncia em imagens de exemplo\n",
    "    """\n",
    "    print(f"üîç Executando infer√™ncia com modelo: {model_path}")\n",
    "    \n",
    "    inference_command = f"""\n",
    "    python detect.py \n",
    "        --weights {model_path} \n",
    "        --source {images_path} \n",
    "        --img 640 \n",
    "        --conf 0.25 \n",
    "        --save-txt \n",
    "        --save-conf \n",
    "        --project {output_path}\n",
    "    """\n",
    "    \n",
    "    print("üíª Comando de infer√™ncia:")\n",
    "    print(inference_command)\n",
    "    \n",
    "    return inference_command\n",
    "\n",
    "# Preparar testes para ambos os modelos\n",
    "models_to_test = [\n",
    "    {\n",
    "        'name': '30 √âpocas',\n",
    "        'path': 'runs/train/farmtech_30_epochs/weights/best.pt',\n",
    "        'output': f'{RESULTS_PATH}/experiment_30_epochs/test_results'\n",
    "    },\n",
    "    {\n",
    "        'name': '60 √âpocas', \n",
    "        'path': 'runs/train/farmtech_60_epochs/weights/best.pt',\n",
    "        'output': f'{RESULTS_PATH}/experiment_60_epochs/test_results'\n",
    "    }\n",
    "]\n",
    "\n",
    "print("üß™ Modelos preparados para teste:")\n",
    "for model in models_to_test:\n",
    "    print(f"   üìã {model['name']}: {model['path']}")\n",
    "\n",
    "print("\n‚ö†Ô∏è  Execute os testes ap√≥s completar os treinamentos")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "results_visualization"
   },
   "source": [
    "## üìà **8. Visualiza√ß√£o de Resultados**\n",
    "\n",
    "Cria√ß√£o de visualiza√ß√µes para demonstrar a efic√°cia dos modelos treinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_visualizations"
   },
   "outputs": [],
   "source": [
    "# Fun√ß√£o para criar tabela de compara√ß√£o final\n",
    "def create_final_comparison_table(results_30, results_60, training_times):\n",
    "    """\n",
    "    Cria tabela comparativa final dos experimentos\n",
    "    """\n",
    "    comparison_data = {\n",
    "        'M√©trica': ['√âpocas', 'mAP@0.5', 'mAP@0.5:0.95', 'Precision', 'Recall', \n",
    "                   'Tempo de Treinamento (min)', 'Overfitting Risk'],\n",
    "        'Experimento 1 (30 √©pocas)': [\n",
    "            30,\n",
    "            f"{results_30['metrics']['mAP_0.5']:.3f}" if results_30 else 'TBD',\n",
    "            f"{results_30['metrics']['mAP_0.5:0.95']:.3f}" if results_30 else 'TBD',\n",
    "            f"{results_30['metrics']['precision']:.3f}" if results_30 else 'TBD',\n",
    "            f"{results_30['metrics']['recall']:.3f}" if results_30 else 'TBD',\n",
    "            f"{training_times['exp1']:.1f}" if 'exp1' in training_times else 'TBD',\n",
    "            'Baixo'\n",
    "        ],\n",
    "        'Experimento 2 (60 √©pocas)': [\n",
    "            60,\n",
    "            f"{results_60['metrics']['mAP_0.5']:.3f}" if results_60 else 'TBD',\n",
    "            f"{results_60['metrics']['mAP_0.5:0.95']:.3f}" if results_60 else 'TBD',\n",
    "            f"{results_60['metrics']['precision']:.3f}" if results_60 else 'TBD',\n",
    "            f"{results_60['metrics']['recall']:.3f}" if results_60 else 'TBD',\n",
    "            f"{training_times['exp2']:.1f}" if 'exp2' in training_times else 'TBD',\n",
    "            'M√©dio'\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    df_comparison = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Estilizar tabela\n",
    "    styled_table = df_comparison.style.set_properties(**{\n",
    "        'background-color': '#f0f0f0',\n",
    "        'color': 'black',\n",
    "        'border-color': 'white'\n",
    "    })\n",
    "    \n",
    "    return df_comparison, styled_table\n",
    "\n",
    "# Fun√ß√£o para mostrar imagens de resultado\n",
    "def display_detection_results(results_path, num_images=4):\n",
    "    """\n",
    "    Exibe resultados de detec√ß√£o em imagens de teste\n",
    "    """\n",
    "    if not os.path.exists(results_path):\n",
    "        print(f"‚ùå Pasta de resultados n√£o encontrada: {results_path}")\n",
    "        return\n",
    "    \n",
    "    # Buscar imagens de resultado\n",
    "    result_images = [f for f in os.listdir(results_path) if f.endswith(('.jpg', '.png'))]\n",
    "    \n",
    "    if not result_images:\n",
    "        print("‚ùå Nenhuma imagem de resultado encontrada")\n",
    "        return\n",
    "    \n",
    "    # Mostrar primeiras imagens\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('üéØ Resultados de Detec√ß√£o - Imagens Processadas', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, img_name in enumerate(result_images[:num_images]):\n",
    "        if i >= 4:  # M√°ximo 4 imagens\n",
    "            break\n",
    "            \n",
    "        img_path = os.path.join(results_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        \n",
    "        axes[row, col].imshow(img_rgb)\n",
    "        axes[row, col].set_title(f'Detec√ß√£o: {img_name}')\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    # Remover subplots vazios\n",
    "    for i in range(len(result_images), 4):\n",
    "        row = i // 2\n",
    "        col = i % 2\n",
    "        axes[row, col].remove()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print("üìä Fun√ß√µes de visualiza√ß√£o criadas!")\n",
    "print("üéØ Use ap√≥s completar os experimentos para gerar relat√≥rios visuais")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "conclusions"
   },
   "source": [
    "## üéØ **9. Conclus√µes e Insights Acad√™micos**\n",
    "\n",
    "### **An√°lise Comparativa Esperada:**\n",
    "\n",
    "#### **Hip√≥teses a Serem Validadas:**\n",
    "\n",
    
